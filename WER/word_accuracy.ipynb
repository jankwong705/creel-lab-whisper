{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from jiwer import wer \n",
    "import os\n",
    "import eng_to_ipa as eti\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_actual(lookup_file, query, type='Sentence'):\n",
    "    df = pd.read_excel(lookup_file)\n",
    "    result = df.loc[df['lookupval'] == query].iloc[0]\n",
    "    return result[type].lower().translate(translator).rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookupval_check(file_name):\n",
    "    check = \"sensical\" not in file_name and \"senseless\" not in file_name and \"nonword\" not in file_name\n",
    "    return check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wer(results, output_file, mode=\"default\", lookup_file=\"lookup_file\"):\n",
    "    input_excel = pd.ExcelFile(results)\n",
    "    match mode:\n",
    "        case \"KT\":\n",
    "            with pd.ExcelWriter(output_file) as writer:\n",
    "                for sheet in input_excel.sheet_names:\n",
    "                    # read excel files\n",
    "                    df = pd.read_excel(results, sheet_name=sheet)\n",
    "                    df = df.drop(0)                                   # drop the separator row\n",
    "                    produced = np.array(df['Predicted'].astype(str))  # columns of whisper-produced sentences\n",
    "                    file_list = np.array(df['File'].astype(str)) \n",
    "\n",
    "                    # convert to all lower cases\n",
    "                    produced = np.array([string.lower() for string in produced])\n",
    "\n",
    "                    # remove all puncutations\n",
    "                    produced = np.array([string.translate(translator) for string in produced])\n",
    "                    expected = np.array([file_name[file_name.rfind('_')+1:file_name.rfind('.')] for file_name in file_list])\n",
    "\n",
    "                    # compute wer\n",
    "                    wer_s = np.array([wer(e, p) for e, p in zip(expected, produced)])\n",
    "\n",
    "                    # add WER to the csv file \n",
    "                    df['WER'] = wer_s\n",
    "\n",
    "                    # output to output_file \n",
    "                    df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "        case \"default\":\n",
    "            with pd.ExcelWriter(output_file) as writer:\n",
    "                for sheet in input_excel.sheet_names:\n",
    "                    # read excel files \n",
    "                    df = pd.read_excel(results, sheet_name=sheet)\n",
    "                    df = df.drop(0)                                   # drop the separator row\n",
    "                    expected = np.array(df['Actual'].astype(str))     # columns of actual sentences\n",
    "                    produced = np.array(df['Predicted'].astype(str))  # columns of whisper-produced sentences\n",
    "\n",
    "                    # convert to all lower cases\n",
    "                    expected = np.array([string.lower() for string in expected])\n",
    "                    produced = np.array([string.lower() for string in produced])\n",
    "\n",
    "                    # remove all puncutations\n",
    "                    expected = np.array([string.translate(translator) for string in expected])\n",
    "                    produced = np.array([string.translate(translator) for string in produced])\n",
    "\n",
    "                    # compute wer\n",
    "                    wer_s = np.array([wer(e, p) for e, p in zip(expected, produced)])\n",
    "\n",
    "                    # add WER to the csv file \n",
    "                    df['WER'] = wer_s\n",
    "\n",
    "                    # output to output_file \n",
    "                    df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "        case \"lookup\":  \n",
    "            with pd.ExcelWriter(output_file) as writer:\n",
    "                # read excel files \n",
    "                df = pd.read_excel(results)\n",
    "                df = df.drop(0)                                   # drop the separator row\n",
    "                produced = np.array(df['Predicted'].astype(str))  # columns of whisper-produced sentences\n",
    "                file_list = np.array(df['File'].astype(str))\n",
    "\n",
    "                # convert to all lower cases\n",
    "                produced = np.array([string.lower().rstrip() for string in produced])\n",
    "\n",
    "                # remove all puncutations\n",
    "                produced = np.array([string.translate(translator) for string in produced])\n",
    "\n",
    "                # compute wer\n",
    "                wer_l = []\n",
    "                expect_l = []\n",
    "                for p in range(produced.shape[0]):\n",
    "                    file_name = file_list[p]\n",
    "                    # check to see if file_name matches format\n",
    "                    if lookupval_check(file_name):\n",
    "                        expect_l.append(\"Query not found!\")\n",
    "                        print(\"Query not found:\", file_name)\n",
    "                        wer_l.append(-1)                        # -1 will be appended if query not found\n",
    "                        continue\n",
    "                    if \"WRONG\" in file_name:\n",
    "                        expect_l.append(\"Query not found!\")\n",
    "                        print(\"Query not found:\", file_name)\n",
    "                        wer_l.append(-1)\n",
    "                        continue\n",
    "                    # extract query from file_name for lookups\n",
    "                    query = file_name[file_name.index('_') + 1:-4] + file_name[8:file_name.index('_')]\n",
    "                    word = produced[p] \n",
    "                    if \"sent\" in file_name: # comparing sentences\n",
    "                        expected = lookup_actual(lookup_file, query, type='Sentence')\n",
    "                        expect_l.append(expected)\n",
    "                        wer_s = wer(expected, word)\n",
    "                        wer_l.append(wer_s)\n",
    "                    else:\n",
    "                        if ' ' in word: # comparing last words\n",
    "                            word = word[word.rfind(' '):]   # extract last word from sentnece\n",
    "                        expected = lookup_actual(lookup_file, query, type='FinalWord')\n",
    "                        expect_l.append(expected)\n",
    "                        wer_s = wer(expected, word)\n",
    "                        wer_l.append(wer_s)\n",
    "                        \n",
    "                # add WER to the csv file \n",
    "                df['Actual'] = np.array(expect_l)\n",
    "                df['WER'] = np.array(wer_l)\n",
    "\n",
    "                # output to output_file \n",
    "                df.to_excel(writer)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_wer(\"US&MX_database_output.xlsx\", \"US&MX_database_wer.xlsx\", mode=\"lookup\", lookup_file=\"USMXlookup.xlsx\")\n",
    "# calculate_wer(\"US&MX_datatiny_output.xlsx\", \"US&MX_datatiny_wer.xlsx\", mode=\"lookup\", lookup_file=\"USMXlookup.xlsx\")\n",
    "# calculate_wer(\"US&MX_datasmall_output.xlsx\", \"US&MX_datasmall_wer.xlsx\", mode=\"lookup\", lookup_file=\"USMXlookup.xlsx\")\n",
    "# calculate_wer(\"US&MX_datamedium_output.xlsx\", \"US&MX_datamedium_wer.xlsx\", mode=\"lookup\", lookup_file=\"USMXlookup.xlsx\")\n",
    "# calculate_wer(\"US&MX_datalarge_output.xlsx\", \"US&MX_datalarge_wer.xlsx\", mode=\"lookup\", lookup_file=\"USMXlookup.xlsx\")\n",
    "# calculate_wer(\"US&MX/US&MXhumantranscriptions.xlsx\", \"US&MXhumantranscriptions_wer_full.xlsx\", mode=\"lookup\", lookup_file=\"US&MX/USMXlookup.xlsx\")\n",
    "# calculate_wer(\"KT_results_tiny.xlsx\", \"KT_results_tiny_wer.xlsx\", mode=\"KT\")\n",
    "# calculate_wer(\"KT_results_small.xlsx\", \"KT_results_small_wer.xlsx\", mode=\"KT\")\n",
    "# calculate_wer(\"KT_results_medium.xlsx\", \"KT_results_medium_wer.xlsx\", mode=\"KT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ipa(input):\n",
    "    # read excel files \n",
    "    df = pd.read_excel(input)\n",
    "    df = df.drop(0)             # drop the separator row\n",
    "    produced = np.array(df['Predicted'].astype(str))\n",
    "    produced = [eti.convert(word) for word in produced]\n",
    "    return produced"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
